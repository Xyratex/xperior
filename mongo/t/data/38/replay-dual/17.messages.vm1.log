==> /var/log/messages <==
Mar 16 04:22:02 mft01 kernel: Lustre: DEBUG MARKER: only running test 17
Mar 16 04:22:02 mft01 kernel: Lustre: DEBUG MARKER: excepting tests: 15c
Mar 16 04:22:02 mft01 kernel: Lustre: DEBUG MARKER: Using TIMEOUT=20
Mar 16 04:22:13 mft01 kernel: Lustre: DEBUG MARKER: == replay-dual test 17: fail OST during recovery (3571) == 04:22:12 (1331864532)
Mar 16 04:22:13 mft01 kernel: LustreError: 8838:0:(filter.c:4624:filter_iocontrol()) *** setting device unknown-block(7,1) read-only ***
Mar 16 04:22:13 mft01 kernel: Turning device loop1 (0x700001) read-only
Mar 16 04:22:13 mft01 kernel: Lustre: DEBUG MARKER: ost1 REPLAY BARRIER on lustre-OST0000
Mar 16 04:22:13 mft01 kernel: Lustre: DEBUG MARKER: local REPLAY BARRIER on lustre-OST0000
Mar 16 04:22:13 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff8800762b5f00
Mar 16 04:22:13 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff8800762b5e98
Mar 16 04:22:13 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff8800762b5e30
Mar 16 04:22:13 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff8800762b5e98
Mar 16 04:22:15 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff880078dd6748
Mar 16 04:22:15 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff880078c7ba20
Mar 16 04:22:15 mft01 kernel: Lustre: Failing over lustre-OST0000
Mar 16 04:22:15 mft01 kernel: Lustre: Skipped 24 previous similar messages
Mar 16 04:22:15 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff8800762b58e8
Mar 16 04:22:15 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff8800762b5880
Mar 16 04:22:15 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff8800762b5818
Mar 16 04:22:17 mft01 kernel: Lustre: lustre-OST0000: shutting down for failover; client state will be preserved.
Mar 16 04:22:17 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff8800762b57b0
Mar 16 04:22:17 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff8800762b5748
Mar 16 04:22:17 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff8800762b56e0
Mar 16 04:22:17 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff8800762b5748
Mar 16 04:22:17 mft01 kernel: Lustre: OST lustre-OST0000 has stopped.
Mar 16 04:22:20 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff880078dd6748
Mar 16 04:22:20 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff880078cb3268
Mar 16 04:22:20 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff880078d11950
Mar 16 04:22:20 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff880078d118e8
Mar 16 04:22:20 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff880078d118e8
Mar 16 04:22:20 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff880078d118e8
Mar 16 04:22:20 mft01 kernel: Write to readonly device loop1 (0x700001) bi_flags: f000000000000001, bi_vcnt: 1, bi_idx: 0, bi->size: 4096, bi_cnt: 2, bi_private: ffff880078d11950
Mar 16 04:22:20 mft01 kernel: Removing read-only on unknown block (0x700001)
Mar 16 04:22:22 mft01 kernel: Lustre: lustre-OST0000-osc-ffff88007710b400: Connection to service lustre-OST0000 via nid 0@lo was lost; in progress operations using this service will wait for recovery to complete.
Mar 16 04:22:22 mft01 kernel: Lustre: Skipped 3 previous similar messages
Mar 16 04:22:22 mft01 kernel: LustreError: 137-5: UUID 'lustre-OST0000_UUID' is not available  for connect (no target)
Mar 16 04:22:27 mft01 kernel: Lustre: 1630:0:(import.c:526:import_select_connection()) lustre-OST0000-osc-ffff88007710b400: tried all connections, increasing latency to 6s
Mar 16 04:22:27 mft01 kernel: LustreError: 137-5: UUID 'lustre-OST0000_UUID' is not available  for connect (no target)
Mar 16 04:22:27 mft01 kernel: LustreError: Skipped 1 previous similar message
Mar 16 04:22:30 mft01 kernel: LDISKFS-fs (loop1): recovery complete
Mar 16 04:22:30 mft01 kernel: LDISKFS-fs (loop1): mounted filesystem with ordered data mode
Mar 16 04:22:30 mft01 kernel: LDISKFS-fs (loop1): mounted filesystem with ordered data mode
Mar 16 04:22:30 mft01 kernel: Lustre: 9011:0:(filter.c:1252:filter_prep_groups()) lustre-OST0000: initialize groups [0,0]
Mar 16 04:22:30 mft01 kernel: Lustre: lustre-OST0000: Now serving lustre-OST0000 on /dev/loop1 with recovery enabled
Mar 16 04:22:30 mft01 kernel: Lustre: lustre-OST0000: Will be in recovery for at least 1:00, or until 3 clients reconnect
Mar 16 04:22:30 mft01 kernel: LustreError: 9003:0:(obd_class.h:1622:obd_notify()) obd lustre-OST0000 has no notify handler
Mar 16 04:22:32 mft01 kernel: Lustre: 1630:0:(import.c:526:import_select_connection()) lustre-OST0000-osc-ffff88007710b400: tried all connections, increasing latency to 11s
Mar 16 04:22:32 mft01 kernel: Lustre: 1630:0:(import.c:526:import_select_connection()) Skipped 1 previous similar message
Mar 16 04:22:32 mft01 kernel: Lustre: 2301:0:(filter.c:2710:filter_connect_internal()) lustre-OST0000: Received MDS connection for group 0
Mar 16 04:22:32 mft01 kernel: Lustre: 2301:0:(filter.c:2710:filter_connect_internal()) Skipped 9 previous similar messages
Mar 16 04:22:51 mft01 kernel: LustreError: 9124:0:(ldlm_lib.c:1859:target_stop_recovery_thread()) lustre-OST0000: Aborting recovery
Mar 16 04:22:51 mft01 kernel: Lustre: 9012:0:(ldlm_lib.c:1558:target_recovery_overseer()) recovery is aborted, evict exports in recovery
Mar 16 04:22:51 mft01 kernel: Lustre: 9012:0:(ldlm_lib.c:1558:target_recovery_overseer()) Skipped 1 previous similar message
Mar 16 04:22:52 mft01 kernel: Lustre: lustre-OST0000: shutting down for failover; client state will be preserved.
Mar 16 04:22:52 mft01 kernel: Lustre: OST lustre-OST0000 has stopped.
Mar 16 04:23:05 mft01 kernel: LDISKFS-fs (loop1): mounted filesystem with ordered data mode
Mar 16 04:23:05 mft01 kernel: LDISKFS-fs (loop1): mounted filesystem with ordered data mode
Mar 16 04:23:06 mft01 kernel: Lustre: 9231:0:(filter.c:1252:filter_prep_groups()) lustre-OST0000: initialize groups [0,0]
Mar 16 04:23:06 mft01 kernel: Lustre: lustre-OST0000: Now serving lustre-OST0000 on /dev/loop1 with recovery enabled
Mar 16 04:23:06 mft01 kernel: Lustre: lustre-OST0000: Will be in recovery for at least 1:00, or until 3 clients reconnect
Mar 16 04:23:06 mft01 kernel: LustreError: 9222:0:(obd_class.h:1622:obd_notify()) obd lustre-OST0000 has no notify handler
Mar 16 04:23:20 mft01 kernel: Lustre: 1629:0:(client.c:1773:ptlrpc_expire_one_request()) @@@ Request  sent has timed out for slow reply: [sent 1331864552/real 1331864552]  req@ffff88007936b800 x1396559449166672/t0(0) o400->lustre-OST0000-osc-ffff88007710b400@0@lo:28/4 lens 192/192 e 2 to 1 dl 1331864600 ref 1 fl Rpc:X/c0/ffffffff rc 0/-1
Mar 16 04:23:20 mft01 kernel: Lustre: 1629:0:(client.c:1773:ptlrpc_expire_one_request()) Skipped 12 previous similar messages
Mar 16 04:24:45 mft01 kernel: Lustre: 9232:0:(ldlm_lib.c:1566:target_recovery_overseer()) recovery is timed out, evict stale exports
Mar 16 04:24:45 mft01 kernel: LustreError: 9232:0:(genops.c:1270:class_disconnect_stale_exports()) lustre-OST0000: disconnect stale client b87f9093-10ae-9a29-9b1b-4e0608534355@<unknown>
Mar 16 04:24:45 mft01 kernel: Lustre: lustre-OST0000-osc-ffff88007710b400: Connection restored to service lustre-OST0000 using nid 0@lo.
Mar 16 04:24:45 mft01 kernel: Lustre: Skipped 2 previous similar messages
Mar 16 04:24:45 mft01 kernel: Lustre: lustre-OST0000: sending delayed replies to recovered clients
Mar 16 04:24:45 mft01 kernel: Lustre: Skipped 4 previous similar messages
Mar 16 04:24:45 mft01 kernel: Lustre: lustre-OST0000: received MDS connection from 0@lo
Mar 16 04:24:45 mft01 kernel: Lustre: Skipped 9 previous similar messages
Mar 16 04:24:45 mft01 kernel: Lustre: 2301:0:(filter.c:2566:filter_llog_connect()) lustre-OST0000: Recovery from log 0x1f/0x0:be68561c
Mar 16 04:24:45 mft01 kernel: Lustre: 2301:0:(filter.c:2566:filter_llog_connect()) Skipped 7 previous similar messages
Mar 16 04:24:45 mft01 kernel: Lustre: MDS mdd_obd-lustre-MDT0000: lustre-OST0000_UUID now active, resetting orphans
Mar 16 04:24:45 mft01 kernel: Lustre: Skipped 9 previous similar messages
Mar 16 04:24:45 mft01 kernel: Lustre: 6795:0:(ldlm_lib.c:873:target_handle_connect()) lustre-MDT0000: connection from 0c0b5934-ef4c-eb36-0de6-24ddd54bfa54@0@lo t0 exp (null) cur 1331864685 last 0
Mar 16 04:24:45 mft01 kernel: Lustre: 6795:0:(ldlm_lib.c:873:target_handle_connect()) Skipped 37 previous similar messages
Mar 16 04:24:49 mft01 kernel: Lustre: DEBUG MARKER: == replay-dual replay-dual.sh test complete, duration 168 sec == 04:24:49 (1331864689)
Mar 16 04:24:49 mft01 kernel: LustreError: 9744:0:(ldlm_request.c:1172:ldlm_cli_cancel_req()) Got rc -108 from cancel RPC: canceling anyway
Mar 16 04:24:49 mft01 kernel: LustreError: 9744:0:(ldlm_request.c:1172:ldlm_cli_cancel_req()) Skipped 7 previous similar messages
Mar 16 04:24:49 mft01 kernel: LustreError: 9744:0:(ldlm_request.c:1799:ldlm_cli_cancel_list()) ldlm_cli_cancel_list: -108
Mar 16 04:24:49 mft01 kernel: LustreError: 9744:0:(ldlm_request.c:1799:ldlm_cli_cancel_list()) Skipped 7 previous similar messages
